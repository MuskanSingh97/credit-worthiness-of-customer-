{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbcb23c-f48c-404f-94f8-fe353485b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steps:\n",
    "\n",
    "# 1. -> Data Collection: You'll need a dataset containing customer details (like income, age, loan amount, etc.) and \n",
    "#a label indicating whether the customer is a good or bad credit risk (often binary: 1 for good credit, 0 for bad credit).\n",
    "\n",
    "# 2. ->Data Preprocessing: Prepare the dataset by handling missing values, encoding categorical features, and splitting it into training and test sets.\n",
    "\n",
    "# 3. ->Model Building: Train machine learning models such as Logistic Regression, Decision Trees, and Random Forests.\n",
    "\n",
    "# 4. ->Evaluation: Evaluate the modelâ€™s performance using accuracy, precision, recall, and AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1486a47c-02b1-4bd9-b036-981b61d871e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.8958\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        15\n",
      "         1.0       0.90      1.00      0.95       129\n",
      "\n",
      "    accuracy                           0.90       144\n",
      "   macro avg       0.45      0.50      0.47       144\n",
      "weighted avg       0.80      0.90      0.85       144\n",
      "\n",
      "AUC Score: 0.5000\n",
      "Confusion Matrix:\n",
      "[[  0  15]\n",
      " [  0 129]]\n",
      "--------------------------------------------------\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.8819\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.53      0.48        15\n",
      "         1.0       0.94      0.92      0.93       129\n",
      "\n",
      "    accuracy                           0.88       144\n",
      "   macro avg       0.69      0.73      0.71       144\n",
      "weighted avg       0.89      0.88      0.89       144\n",
      "\n",
      "AUC Score: 0.7279\n",
      "Confusion Matrix:\n",
      "[[  8   7]\n",
      " [ 10 119]]\n",
      "--------------------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 0.8889\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        15\n",
      "         1.0       0.90      0.99      0.94       129\n",
      "\n",
      "    accuracy                           0.89       144\n",
      "   macro avg       0.45      0.50      0.47       144\n",
      "weighted avg       0.80      0.89      0.84       144\n",
      "\n",
      "AUC Score: 0.4961\n",
      "Confusion Matrix:\n",
      "[[  0  15]\n",
      " [  1 128]]\n",
      "--------------------------------------------------\n",
      "Feature Importance in Random Forest:\n",
      "Loan_Status_Y        0.149602\n",
      "ApplicantIncome      0.082414\n",
      "LoanAmount           0.077074\n",
      "CoapplicantIncome    0.056595\n",
      "Loan_Amount_Term     0.020028\n",
      "                       ...   \n",
      "Loan_ID_LP002205     0.000000\n",
      "Loan_ID_LP002236     0.000000\n",
      "Loan_ID_LP002250     0.000000\n",
      "Loan_ID_LP002255     0.000000\n",
      "Loan_ID_LP001047     0.000000\n",
      "Length: 493, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kc\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kc\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kc\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['credit_scoring_rf_model.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Step 1: Load dataset\n",
    "# Example: 'credit_data.csv' contains features like age, income, loan_amount, credit_history, etc.\n",
    "df = pd.read_csv(r\"C:\\Users\\kc\\Downloads\\loan_data_set.csv\")\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "# Drop missing values (if any) or you can use imputation techniques\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['Credit_History'])  # features (e.g., income, age, loan_amount, credit_history, etc.)\n",
    "y = df['Credit_History']  # target (1 for good credit, 0 for bad credit)\n",
    "\n",
    "# Convert categorical data to numeric using one-hot encoding (if needed)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the feature data (scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 3: Model Building\n",
    "\n",
    "# Logistic Regression Model\n",
    "log_model = LogisticRegression(random_state=42)\n",
    "log_model.fit(X_train, y_train)\n",
    "log_pred = log_model.predict(X_test)\n",
    "\n",
    "# Decision Tree Model\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model_name, y_test, y_pred):\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"AUC Score: {roc_auc_score(y_test, y_pred):.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "evaluate_model(\"Logistic Regression\", y_test, log_pred)\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "evaluate_model(\"Decision Tree\", y_test, tree_pred)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "evaluate_model(\"Random Forest\", y_test, rf_pred)\n",
    "\n",
    "# Step 5: Feature Importance (for Random Forest)\n",
    "feature_importance = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "important_features = pd.Series(feature_importance, index=feature_names).sort_values(ascending=False)\n",
    "print(\"Feature Importance in Random Forest:\")\n",
    "print(important_features)\n",
    "\n",
    "# Step 6: Save the model for future use (optional)\n",
    "import joblib\n",
    "joblib.dump(rf_model, 'credit_scoring_rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8345b04f-dfd5-4656-9fea-8ddba4fec840",
   "metadata": {},
   "outputs": [],
   "source": [
    "### *Explanation of Code:*\n",
    "\n",
    "#1. *Data Preprocessing:*\n",
    " #  - The dataset is loaded and cleaned (removing missing values).\n",
    "   #- The target variable (credit_score) is binary (1 for good credit and 0 for bad credit).\n",
    "   #- Categorical variables are one-hot encoded, and numeric variables are standardized using StandardScaler to normalize the data.\n",
    "   #- The data is split into training and test sets using train_test_split().\n",
    "\n",
    "#2. *Model Building:*\n",
    "   #- Three models are built: Logistic Regression, Decision Tree, and Random Forest.\n",
    "  # - Each model is trained on the training data and predictions are made on the test data.\n",
    "\n",
    "#3. *Model Evaluation:*\n",
    "  # - The evaluate_model() function computes key metrics like accuracy, classification report (precision, recall, F1-score), AUC score,\n",
    "  #     and a confusion matrix for each model.\n",
    "  # - This allows you to compare the models and choose the best one based on performance.\n",
    "\n",
    "#4. *Feature Importance (Random Forest):*\n",
    "  # - For Random Forest, feature importance is extracted to understand which features contribute most to predicting creditworthiness.\n",
    "\n",
    "#5. *Model Saving:*\n",
    "   #- The Random Forest model is saved using joblib.dump() so it can be reused without retraining.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32509138-2ccb-4ece-bfbc-2b857980a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's a detailed explanation of the output:\n",
    "\n",
    "### **Logistic Regression Model**:\n",
    "#1. **Accuracy**: The model achieved 89.58% accuracy, meaning it correctly predicted the credit history (good/bad) in about 90% of the cases.\n",
    "   \n",
    "#2. **Classification Report**:\n",
    "#   - **Precision, Recall, F1-Score** for each class (0: bad credit, 1: good credit):\n",
    "#     - For class `0` (bad credit), precision, recall, and f1-score are all `0`. This means the model failed to predict any \n",
    " #      `bad credit` cases (all `15` actual bad credit cases were incorrectly predicted as `good credit`).\n",
    " #    - For class `1` (good credit), precision is `0.90`, recall is `1.00`, and the f1-score is `0.95`.\n",
    " #        This means most `good credit` cases were correctly predicted.\n",
    " #  - **Support** refers to the number of instances of each class (15 for bad credit and 129 for good credit).\n",
    "\n",
    "#3. **AUC Score**: The AUC score is `0.50`, which suggests that the model is no better than random guessing at\n",
    "#       distinguishing between the two classes (since `0.5` is the baseline for a random classifier).\n",
    "   \n",
    "#4. **Confusion Matrix**: \n",
    "#   - Out of 15 bad credit cases, the model predicted 0 correctly.\n",
    "#   - For the 129 good credit cases, the model correctly predicted all 129.\n",
    "   \n",
    "### **Decision Tree Model**:\n",
    "#1. **Accuracy**: The model achieved 88.19% accuracy.\n",
    "   \n",
    "#2. **Classification Report**:\n",
    " #  - **Class 0** (bad credit): Precision is `0.44`, recall is `0.53`, and f1-score is `0.48`, \n",
    " #   indicating that the model detected some bad credit cases, but it's still far from ideal.\n",
    "  # - **Class 1** (good credit): Precision is `0.94`, recall is `0.92`, and f1-score is `0.93`,\n",
    "   #    meaning the model performed well for good credit cases.\n",
    "   \n",
    "#3. **AUC Score**: The AUC score is `0.7279`, indicating that the decision tree is better at distinguishing between\n",
    "  #         the two classes than the logistic regression model.\n",
    "\n",
    "#4. **Confusion Matrix**:\n",
    " #  - Out of 15 bad credit cases, the model predicted 8 correctly.\n",
    " #  - For the 129 good credit cases, it predicted 119 correctly.\n",
    "\n",
    "### **Random Forest Model**:\n",
    "#1. **Accuracy**: The model achieved 88.89% accuracy.\n",
    "   \n",
    "#2. **Classification Report**:\n",
    "#   - **Class 0** (bad credit): Precision, recall, and f1-score are all `0`, meaning that, like the logistic regression model,\n",
    " #          the random forest model failed to predict any bad credit cases.\n",
    "  # - **Class 1** (good credit): Precision is `0.90`, recall is `0.99`, and f1-score is `0.94`, showing that it predicted good credit cases very well.\n",
    "   \n",
    "#3. **AUC Score**: The AUC score is `0.4961`, which, like the logistic regression model, \n",
    "#     indicates the model is not able to differentiate between the two classes (worse than the decision tree).\n",
    "\n",
    "#4. **Confusion Matrix**:\n",
    " #  - Out of 15 bad credit cases, the model predicted none correctly.\n",
    "  # - For the 129 good credit cases, the model predicted 128 correctly.\n",
    "\n",
    "### **Feature Importance (Random Forest)**:\n",
    "#The feature importance ranking shows which features were most significant in the random forest model's decision-making process. The top 3 features are:\n",
    "#   - `Loan_Status_Y` (probably indicating whether the loan was approved),\n",
    " #  - `ApplicantIncome` (the applicant's income),\n",
    "  # - `LoanAmount` (the loan amount requested).\n",
    "   \n",
    "#Many other features, like individual loan IDs (e.g., `Loan_ID_LP002205`), were deemed unimportant, with an importance value of `0.000000`.\n",
    "\n",
    "### **Conclusion**:\n",
    "#- **Logistic Regression** and **Random Forest** models have a high accuracy but struggle to predict the minority class (`bad credit` cases) effectively.\n",
    "#- **Decision Tree** is better at identifying both good and bad credit cases, as reflected in its higher AUC score and more balanced confusion matrix.\n",
    "#- **Feature Importance** shows that certain variables like loan status and income have a large influence on the model's predictions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
